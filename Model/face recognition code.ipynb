{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec2a9afe",
   "metadata": {},
   "source": [
    "# Face recognition Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d1735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "frame_resizing = 0.25\n",
    "\n",
    "def load_encoding_images(images_path):\n",
    "    \"\"\"\n",
    "    Load encoding images from path\n",
    "    :param images_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Load Images\n",
    "    images_path = glob.glob(os.path.join(images_path, \"*.*\"))\n",
    "\n",
    "    print(\"{} encoding images found.\".format(len(images_path)))\n",
    "\n",
    "    # Store image encoding and names\n",
    "    for img_path in images_path:\n",
    "        img = cv2.imread(img_path)\n",
    "        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Get the filename only from the initial file path.\n",
    "        basename = os.path.basename(img_path)\n",
    "        (filename, ext) = os.path.splitext(basename)\n",
    "        # Get encoding\n",
    "        img_encoding = face_recognition.face_encodings(rgb_img)[0]\n",
    "\n",
    "        # Store file name and file encoding\n",
    "        known_face_encodings.append(img_encoding)\n",
    "        known_face_names.append(filename)\n",
    "    print(\"Encoding images loaded\")\n",
    "\n",
    "def detect_known_faces(frame):\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    # Find all the faces and face encodings in the current frame of video\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "    face_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        # See if the face is a match for the known face(s)\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # # If a match was found in known_face_encodings, just use the first one.\n",
    "        # if True in matches:\n",
    "        #     first_match_index = matches.index(True)\n",
    "        #     name = known_face_names[first_match_index]\n",
    "\n",
    "        # Or instead, use the known face with the smallest distance to the new face\n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[best_match_index]\n",
    "        face_names.append(name)\n",
    "\n",
    "    return face_names\n",
    "\n",
    "# Encode faces from a folder\n",
    "load_encoding_images(\"images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d13c9ec",
   "metadata": {},
   "source": [
    "# Head pose detection code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04126816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "def head_pose_estimation(image):\n",
    "    # Flip the image horizontally for a later selfie-view display\n",
    "    # Also convert the color space from BGR to RGB\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # To improve performance\n",
    "    image.flags.writeable = False\n",
    "\n",
    "    # Get the result\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    # To improve performance\n",
    "    image.flags.writeable = True\n",
    "\n",
    "    # Convert the color space from RGB to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    img_h, img_w, img_c = image.shape\n",
    "    face_3d = []\n",
    "    face_2d = []\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                if idx == 33 or idx == 263 or idx == 1 or idx == 61 or idx == 291 or idx == 199:\n",
    "                    if idx == 1:\n",
    "                        nose_2d = (lm.x * img_w, lm.y * img_h)\n",
    "                        nose_3d = (lm.x * img_w, lm.y * img_h, lm.z * 3000)\n",
    "\n",
    "                    x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "\n",
    "                    # Get the 2D Coordinates\n",
    "                    face_2d.append([x, y])\n",
    "\n",
    "                    # Get the 3D Coordinates\n",
    "                    face_3d.append([x, y, lm.z])       \n",
    "\n",
    "        # Convert it to the NumPy array\n",
    "        face_2d = np.array(face_2d, dtype=np.float64)\n",
    "\n",
    "        # Convert it to the NumPy array\n",
    "        face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "        # The camera matrix\n",
    "        focal_length = 1 * img_w\n",
    "\n",
    "        cam_matrix = np.array([ [focal_length, 0, img_h / 2],\n",
    "                                [0, focal_length, img_w / 2],\n",
    "                                [0, 0, 1]])\n",
    "\n",
    "        # The distortion parameters\n",
    "        dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "        # Solve PnP\n",
    "        success, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "\n",
    "        # Get rotational matrix\n",
    "        rmat, jac = cv2.Rodrigues(rot_vec)\n",
    "\n",
    "        # Get angles\n",
    "        angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "\n",
    "        # Get the y rotation degree\n",
    "        x = angles[0] * 360\n",
    "        y = angles[1] * 360\n",
    "        z = angles[2] * 360\n",
    "\n",
    "        # See where the user's head tilting\n",
    "        direction='Forward'\n",
    "        if y < -10:\n",
    "            direction=\"Looking Left\"\n",
    "        elif y > 10:\n",
    "            direction=\"Looking Right\"\n",
    "        elif x < -10:\n",
    "            direction=\"Looking Down\"\n",
    "        elif x > 10:\n",
    "            direction=\"Looking Up\"\n",
    "\n",
    "        return direction\n",
    "print(\"Done...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0570dda9",
   "metadata": {},
   "source": [
    "# Server code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ff714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# server code\n",
    "\n",
    "import base64\n",
    "import os\n",
    "from io import BytesIO\n",
    "from flask import Flask , request \n",
    "from flask_cors import CORS\n",
    "from codecs import encode\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route(\"/test-image\",methods=[\"POST\"])\n",
    "def test_image():\n",
    "     #getting the base64 image string from the JSON in the request\n",
    "    image_b64 = request.json['image']\n",
    "    parts = image_b64.split('base64,')\n",
    "    #getting the image data \n",
    "    data = parts[1]\n",
    "    \n",
    "    #decoding the image\n",
    "    bytes_img = encode(data, 'utf-8')\n",
    "    binary_img = base64.decodebytes(bytes_img)\n",
    "    image = Image.open(BytesIO(binary_img))\n",
    "    image_ndarray = np.array(image)\n",
    "    \n",
    "    # preforming the face recognition \n",
    "    face_names = detect_known_faces(image_ndarray)\n",
    "    \n",
    "    return {'message': 'Image scaned successfully.','username':str(face_names)}, 200\n",
    "\n",
    "\n",
    "@app.route('/save-image', methods=['POST'])\n",
    "def save_image():\n",
    "     #getting the base64 image string from the JSON in the request\n",
    "    image_b64 = request.json['image']\n",
    "    name = request.json['username']\n",
    "    parts = image_b64.split('base64,')\n",
    "    #getting the image data \n",
    "    data = parts[1]\n",
    "    \n",
    "    #decoding the image\n",
    "    bytes_img = encode(data, 'utf-8')\n",
    "    binary_img = base64.decodebytes(bytes_img)\n",
    "    image = Image.open(BytesIO(binary_img))\n",
    "\n",
    "    #saving the image\n",
    "    save_path = f\"images/{name}.png\"\n",
    "    if os.path.exists(save_path):\n",
    "        return {'message': f\"A file with the name {name}.png already exists in the images folder.\"}, 200\n",
    "    else:\n",
    "        image.save(save_path)\n",
    "        load_encoding_images(\"images/\")\n",
    "    return {'message': 'Image saved successfully.'}, 200\n",
    "\n",
    "@app.route(\"/test-headPose\",methods=[\"POST\"])\n",
    "def test_headPose():\n",
    "     #getting the base64 image string from the JSON in the request\n",
    "    image_b64 = request.json['image']\n",
    "    parts = image_b64.split('base64,')\n",
    "    #getting the image data \n",
    "    data = parts[1]\n",
    "    \n",
    "    #decoding the image\n",
    "    bytes_img = encode(data, 'utf-8')\n",
    "    binary_img = base64.decodebytes(bytes_img)\n",
    "    image = Image.open(BytesIO(binary_img))\n",
    "    image_ndarray = np.array(image)\n",
    "    \n",
    "    # preforming the facePose detection \n",
    "    head_pose = head_pose_estimation(image_ndarray)\n",
    "    \n",
    "    return {'message': 'Image scaned successfully.','headpose':str(head_pose)}, 200\n",
    "\n",
    "@app.route(\"/rename-image\",methods=[\"POST\"])\n",
    "def rename_image():\n",
    "     # getting the old and new image name from the JSON in the request\n",
    "    old_name = request.json['oldName']\n",
    "    new_name = request.json['newName']\n",
    "    old_path = f'images/{old_name}.png'\n",
    "    new_path = f'images/{new_name}.png'\n",
    "    # check if image exists\n",
    "    if os.path.exists(old_path):\n",
    "        os.rename(old_path, new_path)\n",
    "        return {'message': 'Image renamed successfully.'}, 200\n",
    "    else:\n",
    "        return {'message': f\"The file {old_path} does not exist.\"}, 200\n",
    "\n",
    "if __name__=='__main__':\n",
    "   app.run(debug=False,port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f92f5",
   "metadata": {},
   "source": [
    "# Using camera to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3612c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    # Detect Faces\n",
    "    face_locations, face_names = detect_known_faces(frame)\n",
    "    for face_loc, name in zip(face_locations, face_names):\n",
    "        y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
    "\n",
    "        cv2.putText(frame, name,(x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 200), 2)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 200), 4)\n",
    "                \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
